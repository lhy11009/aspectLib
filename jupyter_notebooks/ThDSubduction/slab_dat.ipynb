{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the environment of py-gplate\n",
    "import sys\n",
    "import gplately\n",
    "import numpy as np\n",
    "import gplately.pygplates as pygplates\n",
    "from gplately import ptt\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import gridspec\n",
    "import cartopy.crs as ccrs\n",
    "from plate_model_manager import PlateModelManager\n",
    "import json\n",
    "import math\n",
    "\n",
    "# directory to the aspect Lab\n",
    "ASPECT_LAB_DIR = os.environ['ASPECT_LAB_DIR']\n",
    "sys.path.append(ASPECT_LAB_DIR)\n",
    "RESULT_DIR = os.path.join(ASPECT_LAB_DIR, 'results')\n",
    "import shilofue.GPlateLib as GPlateLib\n",
    "# import utilities in subdirectiory\n",
    "sys.path.append(os.path.join(ASPECT_LAB_DIR, 'utilities', \"python_scripts\"))\n",
    "import Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow for Subduction Dataset from Plate Reconstruction\n",
    "\n",
    "#### General workflow\n",
    "\n",
    "This workflow defines the steps to query a subduction plate dataset based on plate reconstruction data.\n",
    "\n",
    "##### Step 1: Loading Plate Reconstruction Data\n",
    "To extract additional properties such as **plate name**, **start time**, and **end time**, it is necessary to load the plate reconstruction files.\n",
    "\n",
    "##### Step 2: Fixing Subducting Plate Age\n",
    "To accurately determine the age of the subducting plate, we must ensure that the points are correctly pinned to the subducting plate. This involves two workflows:\n",
    "\n",
    "1. **Automatic Workflow**: The process attempts to automatically pin the points to the subducting plate.\n",
    "2. **Manual Workflow**: If the automatic workflow produces invalid values, the manual workflow is used to correct these errors.\n",
    "\n",
    "The results of both workflows are recorded in a CSV file, which can be loaded for further analysis.\n",
    "\n",
    "##### Step 3: Extracting Key Information\n",
    "The ultimate goal of the workflow is to pin sample points to the global subduction zones and extract the following information:\n",
    "\n",
    "- **Location of points**: Geographic coordinates of the sample points.\n",
    "- **Length of the arc**: The arc length of the subduction zone.\n",
    "- **Plate age**: The age of the subducting plate at the pinned location.\n",
    "- **Convergence rate**: The rate of convergence between the plates.\n",
    "- **Trench mobility**: The movement of the trench over time.\n",
    "- **Trench PID**: The process ID (PID) for the trench, as used in the reconstruction.\n",
    "- **Subduction PID**: The process ID (PID) for the subduction zone, as used in the reconstruction.\n",
    "\n",
    "> **Note**: The **trench PID** and **subduction PID** correspond to the IDs used in the plate reconstruction process.\n",
    "\n",
    "\n",
    "#### To get a good dataset for a time step\n",
    "\n",
    "1. **Select the Automatic Workflow and get a global dataset**:\n",
    "   - Use the global dataset with the automatic workflow to initiate the data processing. This is a good reference dataset to refine points of respective trenches\n",
    "\n",
    "\n",
    "2. **Look in the global dataset for a local subset or extract a Local dataset directly**:\n",
    "    - To directly extract a local dataset, look for a id for a trench. Put that in the workflow to extract a single trench\n",
    "    - When we are satisfied, damp the data in to a finalized dataset\n",
    "\n",
    "3. **Analyze the Finalzed Dataset** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "First assign a reconstruction time\n",
    "\n",
    "Here I need a file to lookup ids and names of the subductions for each reconstruction time.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a reconstruction time\n",
    "reconstruction_time=0 # time of reconstruction, must be integar\n",
    "\n",
    "# enter the directory of the plate reconstruction files and check\n",
    "dir_re = os.path.join(ASPECT_LAB_DIR, \"dtemp/gplate_export_test0/Muller_etal_2019_PlateBoundaries_no_topologies\")\n",
    "assert(os.path.isdir(dir_re))\n",
    "\n",
    "# initiate the class\n",
    "GClass = GPlateLib.GPLATE_CLASS()\n",
    "GParseReconstruction = GPlateLib.PARSERECONSTRUCTION()\n",
    "\n",
    "\n",
    "GClass.SetReconstructionTime(reconstruction_time)\n",
    "GClass.Reconstruct()\n",
    "\n",
    "infile = os.path.join(dir_re, \"reconstructed_%.2dMa.xy\" % reconstruction_time)\n",
    "GParseReconstruction.ReadFile(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search a Single Subduction Zone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search with a key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GParseReconstruction.trench_names)\n",
    "\n",
    "keyword = \"ryu\"\n",
    "\n",
    "matching_indices = [i for i, name in enumerate(GParseReconstruction.trench_names) if keyword.lower() in name.lower()]\n",
    "for index in matching_indices:\n",
    "    print(index)\n",
    "    print(\"name: \", GParseReconstruction.trench_names[index])\n",
    "    print(\"id: \", GParseReconstruction.trench_pids[index])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search with a trench id\n",
    "\n",
    "In order to do this, first lookup in a global dataset. Then use the following block to query for the data\n",
    "\n",
    "##### trench id, t = 0\n",
    "* 12001, ,CAS\n",
    "* 686, Indonesian bndy w AUS-mg, ANDA-SUM\n",
    "* 736, Java SZ\n",
    "* 651, Flores Banda SZ, JAVA\n",
    "* 669, North Sulawesi Subduction, SULA\n",
    "* 612, Luzon subduction, LUZ\n",
    "* 678, Philippine trench, PHIL\n",
    "* 648, Okinawa Trough (Ryuku) from EarthByte cob MG 4-20-07\n",
    "* 659, Izu Bonin Trench\n",
    "* 699, Marianas Trench-NUVEL\n",
    "* 111, Aleutian and Bering Sea Masking Polygon\n",
    "* 406, Kamchatka SZ from EarthByte COB at 0Ma -- MG 4/20/07\n",
    "* 413, Shirshov Ridge Subduction (not included), part of 901 (subduction id)\n",
    "* 2000, Central American subduction from 135 Ma\n",
    "* 201, South America trench taken from a combination of RUM and COB file\n",
    "* 2031, Caribbean/farallon subduction iniating at 85 Ma\n",
    "* 2011, Caribbean subduction\n",
    "* 815, Sandwich Trench\n",
    "* 821, Tonga-Kermadec-MG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_pid = 111\n",
    "_name = GParseReconstruction.LookupNameByPid(trench_pid)\n",
    "print(_name)\n",
    "\n",
    "# get the data of this subduction zone\n",
    "one_subduction_data = GClass.GetOneSubductionByTrenchId(trench_pid)\n",
    "\n",
    "# basic plots\n",
    "# plot the reconstructed zone\n",
    "fig = plt.figure(figsize=(10,6), dpi=100)\n",
    "ax = fig.add_subplot(111, projection=ccrs.Mollweide(central_longitude = 180))\n",
    "gl=ax.gridlines(color='0.7',linestyle='--', xlocs=np.arange(-180,180,15), ylocs=np.arange(-90,90,15))\n",
    "gl.left_labels = True\n",
    "plt.title(f'{reconstruction_time} Ma')\n",
    "# you may change the extent to global to see the sample points in a world map.\n",
    "ax.set_global()\n",
    "# ax.set_extent([-80,0,-70,0])\n",
    "# plot the coastline\n",
    "GClass.PlotCoastlines(ax)\n",
    "#GClass.gplot.plot_trenches(ax, color='k')\n",
    "#GClass.gplot.plot_subduction_teeth(ax, color='k')\n",
    "# plot the seafloor age\n",
    "im_age = GClass.PlotSeaFloorAges(ax)\n",
    "\n",
    "# plot the subduction zone\n",
    "im_sub = ax.scatter(one_subduction_data.lon, one_subduction_data.lat, marker=\".\", s=3, c='r', transform=ccrs.PlateCarree())\n",
    "\n",
    "# set plot options\n",
    "cbar_age = plt.colorbar(im_age) # colorbar for ages\n",
    "cbar_age.ax.get_yaxis().labelpad = 15\n",
    "cbar_age.ax.set_ylabel(\"Age (Ma)\", rotation=90)\n",
    "cbar = plt.colorbar(im_sub) # colorbar for trenches\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "# cbar.ax.set_ylabel('Trench Velocity Magnitude (in cm/yr)', rotation=90) # choose between these two labels to use for trenches\n",
    "cbar.ax.set_ylabel('Convergence Velocity Magnitude (in cm/yr)', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow to extract a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Methodology\n",
    "\n",
    "In this section, we define the methodology for working with the subduction dataset.\n",
    "\n",
    "1. **Loading Data**: \n",
    "   - You can choose to either load an existing CSV file containing previously saved data or start the process from scratch.\n",
    "\n",
    "2. **Sampling Trenches**:\n",
    "   - You can choose between two sampling methods:\n",
    "     - **Sample all trenches at once**: This option allows you to sample all trenches in a single operation.\n",
    "     - **Sample a specific trench**: Alternatively, you can focus on sampling a single trench for more granular analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by a give arc length edge and resample section\n",
    "# arc_length_edge = 0.0; arc_length_resample_section = 2.0  # by degree\n",
    "arc_length_edge = 2.0; arc_length_resample_section = 2.0  # by degree\n",
    "\n",
    "use_recorded_file = True; resample_all = True; trench_pid = None # use this option to start from a recorded file\n",
    "# use_recorded_file = False; resample_all = True; trench_pid = None\n",
    "# use_recorded_file = False; resample_all = False; trench_pid = 2000\n",
    "\n",
    "# resample the subduction zones\n",
    "recorded_file = os.path.join(ASPECT_LAB_DIR, \"files\", \"ThDSubduction\", \"gplate_json_files\", \"subduction_resampled_t_%.2e.csv\" \\\n",
    "                         % (reconstruction_time))\n",
    "# recorded_file = os.path.join(ASPECT_LAB_DIR, \"dtemp\", \"gplate_export_test0\", \"subduction_resampled_t_%.2e_edge_%.2f_section_%.2f.csv\" \\\n",
    "#                            % (reconstruction_time, arc_length_edge, arc_length_resample_section))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_recorded_file:\n",
    "    print(\"use recorded file: \", recorded_file)\n",
    "    assert(os.path.isfile(recorded_file))\n",
    "    subduction_data_resampled = pd.read_csv(recorded_file) \n",
    "else:\n",
    "    if resample_all:\n",
    "        subduction_data_resampled = GClass.ResampleAllSubduction(arc_length_edge, arc_length_resample_section)\n",
    "    else:\n",
    "        subduction_data_resampled, _ = GClass.ResampleSubductionById(trench_pid, arc_length_edge, arc_length_resample_section)\n",
    "    subduction_data_resampled['age'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "    subduction_data_resampled['lon_fix'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "    subduction_data_resampled['lat_fix'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "    subduction_data_resampled['fix_age_polarity'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "    # todo_ages\n",
    "    subduction_data_resampled['marker'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "    subduction_data_resampled['marker_fill'] = ['none' for i in range(len(subduction_data_resampled))]\n",
    "    subduction_data_resampled['color'] = [np.nan for i in range(len(subduction_data_resampled))]\n",
    "\n",
    "    # fix the ages\n",
    "    GClass.FixTrenchAge(subduction_data_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query for invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the invalid indexes\n",
    "invalid_indexes = []\n",
    "for i in range(len(subduction_data_resampled['age'])):\n",
    "    if np.isnan(subduction_data_resampled['age'][i]):\n",
    "        invalid_indexes.append(i)\n",
    "\n",
    "print(\"len(ages): \")\n",
    "print(len(subduction_data_resampled['age']))\n",
    "print(\"ages: \")\n",
    "print(subduction_data_resampled['age'])\n",
    "print(\"invalid_indexes: \")\n",
    "print(invalid_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix the invalid values\n",
    "\n",
    "First, map out the invalid ages from the outputs from the previous section.\n",
    "\n",
    "Use the index, theta and direction to create a new sampling point interact with the raster data\n",
    "* i_fs: the index\n",
    "* theta_fs: theta of the direction. 0 is north and 180 is south.\n",
    "* d_fs: distance along the direction\n",
    "\n",
    "The next section is for plotting the current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_fs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "# theta_fs = [180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 210.0, 210.0, 150.0, 180.0, 180.0]\n",
    "# d_fs = [100e3, 100e3, 100e3, 100e3, 100e3, 200e3, 400e3, 300e3, 200e3, 300e3, 200e3, 1000e3]\n",
    "# for ii in range(len(i_fs)):\n",
    "#     i_f = i_fs[ii]\n",
    "#     theta_f = theta_fs[ii]\n",
    "#     d_f = d_fs[ii]\n",
    "#     subduction_data_resampled_local = None\n",
    "#     subduction_data_resampled_local = pd.DataFrame([subduction_data_resampled.iloc[i_f]])\n",
    "#     subduction_data_resampled_local.lon, subduction_data_resampled_local.lat = \\\n",
    "#         Utilities.map_point_by_distance(subduction_data_resampled.iloc[i_f].lon, subduction_data_resampled.iloc[i_f].lat, theta_f, d_f)\n",
    "#     new_age = GClass.InterpolateAgeGrid(subduction_data_resampled_local)\n",
    "#     print(i_f, \": new age - \", new_age)\n",
    "#     subduction_data_resampled.loc[i_f, 'age'] = new_age\n",
    "#     if new_age is not np.nan:\n",
    "#         new_lon = subduction_data_resampled_local.lon.values[0]\n",
    "#         new_lat = subduction_data_resampled_local.lat.values[0]\n",
    "#         subduction_data_resampled.loc[i_f, 'lon_fix'] = new_lon\n",
    "#         subduction_data_resampled.loc[i_f, 'lat_fix'] = new_lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix the dataset of Ryuku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ryuku_dataset = pd.DataFrame(np.nan, index=range(5), columns=subduction_data_resampled.columns)\n",
    "\n",
    "# ryuku_dataset['lat'] = [23.4, 24.2, 25.7, 27.5, 29.8]\n",
    "# ryuku_dataset['lon'] = [124.0, 127.0, 129.0, 130.5, 132.0]\n",
    "# ryuku_dataset['age'] = [35.0, 38.0, 48.0, 50.0, 50.0]\n",
    "# ryuku_dataset['trench_velocity']= [3.0, 0.9, 1.2, 0.7, 0.9]\n",
    "\n",
    "# subduction_data_resampled = pd.concat([subduction_data_resampled, ryuku_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add a vector to determined the direction of convergence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subduction_data_resampled['conv_angle_polarity'] = [0.0 for i in range(len(subduction_data_resampled))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic plots\n",
    "# plot the reconstructed zone\n",
    "# i_p = None # plot all\n",
    "i_p = 76 # plot one point\n",
    "fig = plt.figure(figsize=(10,6), dpi=100)\n",
    "ax = fig.add_subplot(111, projection=ccrs.Mollweide(central_longitude = 180))\n",
    "gl=ax.gridlines(color='0.7',linestyle='--', xlocs=np.arange(-180,180,15), ylocs=np.arange(-90,90,15))\n",
    "gl.left_labels = True\n",
    "plt.title(f'{reconstruction_time} Ma')\n",
    "# you may change the extent to global to see the sample points in a world map.\n",
    "ax.set_global()\n",
    "# ax.set_extent([-80,0,-70,0])\n",
    "# plot the coastline\n",
    "GClass.PlotCoastlines(ax)\n",
    "# plot the seafloor age\n",
    "im_age = GClass.PlotSeaFloorAges(ax)\n",
    "# plot all subduction zones and subduction teeth\n",
    "# im_sub = GPlateLib.plot_one_subduction_data(ax, GClass.GetSubductionData())\n",
    "GClass.gplot.plot_trenches(ax, color='k')\n",
    "GClass.gplot.plot_subduction_teeth(ax, color='k')\n",
    "\n",
    "# plot all the fixed ages\n",
    "mask = (~subduction_data_resampled['age'].isna())\n",
    "if i_p is None:\n",
    "    # plot all points\n",
    "    ax.scatter(subduction_data_resampled[mask].lon, subduction_data_resampled[mask].lat, marker=\".\", s=60, c='r', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(subduction_data_resampled[~mask].lon, subduction_data_resampled[~mask].lat, marker=\".\", s=60, c='y', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(subduction_data_resampled[mask].lon_fix, subduction_data_resampled[mask].lat_fix, marker=\".\", s=30, c='c', transform=ccrs.PlateCarree())\n",
    "else:\n",
    "    # plot one point, don't apply mask\n",
    "    ax.scatter(subduction_data_resampled.lon[i_p], subduction_data_resampled.lat[i_p], marker=\".\", s=60, c='r', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(subduction_data_resampled.lon_fix[i_p], subduction_data_resampled.lat_fix[i_p], marker=\".\", s=30, c='c', transform=ccrs.PlateCarree())\n",
    "\n",
    "# set plot options\n",
    "cbar_age = plt.colorbar(im_age) # colorbar for ages\n",
    "cbar_age.ax.get_yaxis().labelpad = 15\n",
    "cbar_age.ax.set_ylabel(\"Age (Ma)\", rotation=90)\n",
    "\n",
    "# write outputs\n",
    "fileout = os.path.join(RESULT_DIR, \"gplate_subduction_zones\", \"subduction_resampled_t_%.2e_edge_%.2f_section_%.2f.pdf\" \\\n",
    "                         % (reconstruction_time, arc_length_edge, arc_length_resample_section))\n",
    "fileout1 = os.path.join(RESULT_DIR, \"gplate_subduction_zones\", \"subduction_resampled_t_%.2e_edge_%.2f_section_%.2f.png\" \\\n",
    "                         % (reconstruction_time, arc_length_edge, arc_length_resample_section))\n",
    "if not (os.path.isdir(os.path.dirname(fileout))):\n",
    "    os.mkdir(os.path.dirname(fileout))\n",
    "fig.savefig(fileout)\n",
    "fig.savefig(fileout1)\n",
    "print(\"Save figure: %s\" % fileout)\n",
    "print(\"Save figure: %s\" % fileout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "print(subduction_data_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = True\n",
    "# export the file to a temp file\n",
    "if resample_all:\n",
    "    temp_file = os.path.join(ASPECT_LAB_DIR, \"dtemp\", \"gplate_export_test0\", \"subduction_resampled_t_%.2e_edge_%.2f_section_%.2f.csv\" \\\n",
    "                            % (reconstruction_time, arc_length_edge, arc_length_resample_section))\n",
    "else:\n",
    "    temp_file = os.path.join(ASPECT_LAB_DIR, \"dtemp\", \"gplate_export_test0\", \"subduction_resampled_t_%.2e_pid_%d_edge_%.2f_section_%.2f.csv\" \\\n",
    "                         % (reconstruction_time, int(trench_pid), arc_length_edge, arc_length_resample_section))\n",
    "\n",
    "# don't mess up the existing files\n",
    "if record_file:\n",
    "    subduction_data_resampled.to_csv(temp_file)\n",
    "    print(\"Data saved to %s\" % temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze extracted data set\n",
    "\n",
    "We plot the convergence / trench retreat rate of trenches below.\n",
    "The plot is also combined with a sea floor age\n",
    "\n",
    "Issue: We get a lot of nan value in ages\n",
    "1. check the position of the sample points\n",
    "2. plot the raster of oceanic plate age\n",
    "\n",
    "#### Some notes\n",
    "\n",
    "* ANDA-SUM: The change from trench retreat to advance (as in L05) is missing\n",
    "* JAVA: essientially, I am fixing the ages to one point (on the corner, above Australia); The trench velocity is retreat, instead of advance (L05)\n",
    "* LUZ: gplately data suggest advance of 2.5, while L05 shows fast retreat motion\n",
    "* Ryuku: data is missing in the current dataset, fixing using values form Table 1 in Lallemend et al., 2005\n",
    "* KuKam: data shows retreat motion, while L05 shows advance motion\n",
    "* PER-NCHI-JUAN-SCHI (subduction id 911): These seem to be all in the subduction id 901. Beyond a trench id of 201, the trench id varies from 201010 to 20101?. Up north, the component is marked with trench id 2031 (Caribbean/farallon subduction iniating at 85 Ma).\n",
    "* South to SCHI: This is represented by the subduction id 801, but the trench id 201 continues from the previous 901 subduction.\n",
    "* ANT: retreat motion in this dataset, rather than the advance motion in L05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate a distance to an adjacent subduction zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Geod\n",
    "\n",
    "Ro = 6371e3\n",
    "    \n",
    "# Initialize the Geod object with the WGS84 ellipsoid model, \n",
    "# which provides accurate geodesic calculations on Earth's surface\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, radius=Ro):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in the given radius unit (default is kilometers for Earth)\n",
    "    distance = radius * c\n",
    "    return distance\n",
    "\n",
    "# Record both the minimum distance and the indexing in the dataset\n",
    "subduction_distances = np.zeros(len(subduction_data_resampled))\n",
    "subduction_indexes = np.array(range(len(subduction_data_resampled)))\n",
    "subduction_min_distance_indexes = np.full(len(subduction_data_resampled), -1, dtype=int)\n",
    "subduction_maker_lons = []\n",
    "subduction_maker_lats = []\n",
    "\n",
    "# By default, we assign the length of the equator and compare the computed\n",
    "# distance to the previous value\n",
    "# i_p = None; subducting_pid = None\n",
    "# i_p = 142; subducting_pid = None # plot one point\n",
    "# i_p = None; subducting_pid = 201; trench_pid = None # plot one point\n",
    "i_p = None; subducting_pid = 901; trench_pid = 699 # plot one point\n",
    "\n",
    "# Uncomment this part to modify the values of conv_angle_polarity\n",
    "# if i_p is not None:\n",
    "#   subduction_data_resampled.loc[i_p, \"conv_angle_polarity\"] = 0.0\n",
    "# elif subducting_pid is not None:\n",
    "#   # Figure out the indexes of the selected points and their matching\n",
    "#   # points in the dataset\n",
    "#   mask1 = subduction_data_resampled.subducting_pid == subducting_pid\n",
    "#   if trench_pid is not None:\n",
    "#     mask2 = subduction_data_resampled.trench_pid == trench_pid\n",
    "#   else:\n",
    "#     mask2 = np.ones(len(subduction_data_resampled), dtype=bool)\n",
    "#   mask = (mask1 & mask2)\n",
    "#   subduction_data_resampled.loc[mask, \"conv_angle_polarity\"] = 0.0\n",
    "\n",
    "d_m = 1000e3 # distance of marker point\n",
    "theta_diff = 10.0 # degree\n",
    "for i_1 in range(len(subduction_data_resampled)):\n",
    "  subducting_pid_1 = int(subduction_data_resampled.subducting_pid[i_1])\n",
    "  lat1, lon1 = subduction_data_resampled.lat[i_1], subduction_data_resampled.lon[i_1]\n",
    "  # Pin a marker point with a distance d_m and an angle of convergence (theta, from east)\n",
    "  # Then, get a shortest path connecting the query point and the marker point.\n",
    "  # The direction of convergence varies by assigning a polarity variable\n",
    "  if subduction_data_resampled.conv_angle_polarity[i_1] == 0.0:\n",
    "    theta = subduction_data_resampled.conv_angle[i_1] + 90.0\n",
    "  elif subduction_data_resampled.conv_angle_polarity[i_1] == 1.0:\n",
    "    theta = subduction_data_resampled.conv_angle[i_1] - 90.0\n",
    "  theta = (theta + 360) % 360 # normalize theta\n",
    "  lon_m, lat_m = Utilities.map_point_by_distance(lon1, lat1, theta, d_m)\n",
    "  path_lon_m , path_lat_m = Utilities.shortest_path_between_two_points([lon1, lat1], [lon_m, lat_m], geod.npts, 100)\n",
    "  subduction_maker_lons.append(path_lon_m); subduction_maker_lats.append(path_lat_m) \n",
    "  distance = 2 * np.pi * Ro\n",
    "  for j_2 in range(len(subduction_data_resampled)):\n",
    "    subducting_pid_2 = int(subduction_data_resampled.subducting_pid[j_2])\n",
    "    lat2, lon2 = subduction_data_resampled.lat[j_2], subduction_data_resampled.lon[j_2]\n",
    "    theta_1 = Utilities.calculate_bearing(lon1, lat1, lon2, lat2) # theta_1 is normalized\n",
    "    if j_2 == i_1:\n",
    "      continue\n",
    "    if subducting_pid_1 == subducting_pid_2:\n",
    "      continue\n",
    "    distance_between_points = haversine(lat1, lon1, lat2, lon2)\n",
    "    if distance_between_points < distance and abs(theta_1 - theta) < theta_diff:\n",
    "      distance = distance_between_points\n",
    "      subduction_min_distance_indexes[i_1] = j_2\n",
    "  subduction_distances[i_1] = distance\n",
    "\n",
    "subduction_data_resampled[\"near_distance\"] = subduction_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the matching points of minimum distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_p = 43; subducting_pid = None # plot one point\n",
    "# i_p = None; subducting_pid = 801 # plot one subduction zone\n",
    "\n",
    "# First, the global coastline is plotted\n",
    "fig = plt.figure(figsize=(10,6), dpi=100)\n",
    "ax = fig.add_subplot(111, projection=ccrs.Mollweide(central_longitude = 180))\n",
    "gl=ax.gridlines(color='0.7',linestyle='--', xlocs=np.arange(-180,180,15), ylocs=np.arange(-90,90,15))\n",
    "gl.left_labels = True\n",
    "plt.title(f'{reconstruction_time} Ma')\n",
    "ax.set_global()\n",
    "# plot the coastline\n",
    "GClass.PlotCoastlines(ax)\n",
    "im_age = GClass.PlotSeaFloorAges(ax)\n",
    "GClass.gplot.plot_trenches(ax, color='k')\n",
    "GClass.gplot.plot_subduction_teeth(ax, color='k')\n",
    "\n",
    "# Then, a mask is generated based on the availability of the dataset\n",
    "# mask1 - user selection\n",
    "# mask2 - matched points\n",
    "# mask - mask1 & mask2\n",
    "mask1 = np.ones(len(subduction_data_resampled), dtype=bool)\n",
    "indexes_valid = None\n",
    "if i_p is not None:\n",
    "  min_indexes_valid = subduction_min_distance_indexes[i_p]\n",
    "elif subducting_pid is not None:\n",
    "  # Figure out the indexes of the selected points and their matching\n",
    "  # points in the dataset\n",
    "  mask1 = subduction_data_resampled.subducting_pid == subducting_pid\n",
    "\n",
    "  mask2 = (subduction_min_distance_indexes >= 0)\n",
    "  if trench_pid is not None:\n",
    "    mask3 = subduction_data_resampled.trench_pid == trench_pid\n",
    "  else:\n",
    "    mask3 = np.ones(len(subduction_data_resampled), dtype=bool)\n",
    "\n",
    "  mask = mask1 & mask2 & mask3\n",
    "  mask_in = mask1 & (~mask2) & mask3\n",
    "\n",
    "  min_indexes_valid = subduction_min_distance_indexes[mask]\n",
    "  indexes_valid = subduction_indexes[mask]\n",
    "\n",
    "  min_indexes_invalid = subduction_min_distance_indexes[mask_in]\n",
    "else:\n",
    "  mask = np.ones(len(subduction_data_resampled), dtype=bool)\n",
    "  min_indexes_valid = subduction_min_distance_indexes[mask]\n",
    "  indexes_valid = subduction_indexes[mask]\n",
    "\n",
    "\n",
    "# Here we plot the pairs of matching points in the subduction zones\n",
    "# We also plot the marker path along the direction of local convergence\n",
    "# and a length of d_m\n",
    "if i_p is not None:\n",
    "  # plot the query point\n",
    "  ax.scatter(subduction_data_resampled.lon[i_p], subduction_data_resampled.lat[i_p], marker=\".\", s=60, c='r', transform=ccrs.PlateCarree())\n",
    "  # plot the marker path\n",
    "  ax.scatter(subduction_maker_lons[i_p], subduction_maker_lats[i_p], marker='.', s=5, c='orange', transform=ccrs.PlateCarree())\n",
    "  # plot the matching points\n",
    "  ax.scatter(subduction_data_resampled.lon[min_indexes_valid], subduction_data_resampled.lat[min_indexes_valid], marker=\".\", s=60, c='b', transform=ccrs.PlateCarree())\n",
    "  ax.plot([subduction_data_resampled.lon[i_p], subduction_data_resampled.lon[min_indexes_valid]],\\\n",
    "             [subduction_data_resampled.lat[i_p], subduction_data_resampled.lat[min_indexes_valid]],\\\n",
    "              c='c', transform=ccrs.PlateCarree())\n",
    "else:\n",
    "  # plot the query points\n",
    "  ax.scatter(subduction_data_resampled.lon[mask], subduction_data_resampled.lat[mask], marker=\".\", s=60, c='r', transform=ccrs.PlateCarree())\n",
    "  for i in range(len(min_indexes_valid)):\n",
    "    # plot the marker path\n",
    "    ax.scatter(subduction_maker_lons[indexes_valid[i]], subduction_maker_lats[indexes_valid[i]], marker='.', s=5, c='orange', transform=ccrs.PlateCarree())\n",
    "    # plot the matching points\n",
    "    try:\n",
    "      ax.scatter(subduction_data_resampled.lon[min_indexes_valid[i]], subduction_data_resampled.lat[min_indexes_valid[i]], marker=\".\", s=60, c='b', transform=ccrs.PlateCarree())\n",
    "      ax.plot([subduction_data_resampled.lon[indexes_valid[i]], subduction_data_resampled.lon[min_indexes_valid[i]]],\\\n",
    "             [subduction_data_resampled.lat[indexes_valid[i]], subduction_data_resampled.lat[min_indexes_valid[i]]],\\\n",
    "              c='c', transform=ccrs.PlateCarree())\n",
    "    except KeyError:\n",
    "      pass # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subduction_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot results of analysis\n",
    "Here we generate a variation of the previous plot, by differentiating valid age values and invalid age values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary keys represent subduction zone IDs, and the values specify\n",
    "\n",
    "from matplotlib.path import Path\n",
    "# the marker style, face color, and name associated with that ID.\n",
    "# this definition of snowflake initially has an error in the \"code\" part\n",
    "verts = [\n",
    "    (0., 0.),   # Center\n",
    "    (0.2, 0.6), # Upper arm\n",
    "    (0., 0.),   # Center\n",
    "    (0.4, 0.4), # Right diagonal\n",
    "    (0., 0.),   # Center\n",
    "    (0.6, 0.2), # Right arm\n",
    "    (0., 0.),   # Center\n",
    "    (0.4, -0.4),# Right down diagonal\n",
    "    (0., 0.),   # Center\n",
    "    (0.2, -0.6),# Bottom arm\n",
    "    (0., 0.),   # Center\n",
    "    (-0.4, -0.4),# Left down diagonal\n",
    "    (0., 0.),   # Center\n",
    "    (-0.6, -0.2),# Left arm\n",
    "    (0., 0.),   # Center\n",
    "    (-0.4, 0.4),# Left diagonal\n",
    "    (0., 0.),   # Center\n",
    "    (-0.2, 0.6),# Upper left arm\n",
    "]\n",
    "codes = [Path.MOVETO] + [Path.LINETO, Path.MOVETO] * 8 + [Path.MOVETO]\n",
    "snowflake = Path(verts, codes)\n",
    "\n",
    "# Define vertices for two equilateral triangles\n",
    "vertices = [\n",
    "    [0, 1], [-np.sqrt(3)/2, -0.5], [np.sqrt(3)/2, -0.5], [0, 1],  # First triangle\n",
    "    [0, -1], [-np.sqrt(3)/2, 0.5], [np.sqrt(3)/2, 0.5], [0, -1]   # Second triangle\n",
    "]\n",
    "# Flatten the vertices list for creating the Path\n",
    "vertices = np.array(vertices)\n",
    "# Define path codes (all 'LINETO' except the start 'MOVETO')\n",
    "codes = [Path.MOVETO] + [Path.LINETO] * (len(vertices) - 1)\n",
    "\n",
    "star_path = Path(vertices, codes)\n",
    "\n",
    "plot_options = \\\n",
    "{\n",
    "    903: {\"marker\": 'o',  \"markerfacecolor\": \"yellow\", \"name\": \"CAS\"},\n",
    "    511: {\"marker\": 's',  \"markerfacecolor\": \"yellow\", \"name\": \"ANDA-SUM\"},\n",
    "    801: {\"marker\": 'd',  \"markerfacecolor\": \"yellow\", \"name\": \"JAVA\"},\n",
    "    645: {\"marker\": snowflake,  \"markerfacecolor\": \"black\", \"name\": \"SULA\"},\n",
    "    602: {\"marker\": 'x',  \"markerfacecolor\": \"blue\", \"name\": \"LUZ\"},\n",
    "    608: {\"marker\": 's',  \"markerfacecolor\": 'c', \"name\": \"PHIL\"},\n",
    "    901: {\n",
    "        699: {\"marker\": '>',  \"markerfacecolor\": 'red', \"name\": \"MAR\"},\n",
    "        659: {\"marker\": 's',  \"markerfacecolor\": 'red', \"name\": \"IZU\"},\n",
    "        (601112.0, 601118.0): {\"marker\": '^',  \"markerfacecolor\": 'green', \"name\": \"JAP\"},\n",
    "        406:{\"marker\": 'v',  \"markerfacecolor\": 'green', \"name\": \"KUKAM\"},\n",
    "        111: {\"marker\": 'o',  \"markerfacecolor\": 'pink', \"name\": \"ALE-ALA\"},\n",
    "        (806, 821): {\"marker\": 'd',  \"markerfacecolor\": 'blue', \"name\": \"TON-KERM\"}\n",
    "        },\n",
    "    909: {\"marker\": star_path,  \"markerfacecolor\": 'c', \"name\": \"MEX\"},\n",
    "    911: {\"marker\": 'o',  \"markerfacecolor\": 'k', \"name\": \"PER-NCHI-JUAN-SCHI\"},\n",
    "    802: {\"marker\": 'd',  \"markerfacecolor\": 'k', \"name\": \"SSCHI-TBD\"},\n",
    "    201: {\n",
    "        2011:{\"marker\": '+',  \"markerfacecolor\": 'pink', \"name\": \"ANT\"},\n",
    "        815:{\"marker\": '*',  \"markerfacecolor\": 'r', \"name\": \"SAND\"}\n",
    "        },\n",
    "    1: {\"marker\": 'd',  \"markerfacecolor\": \"r\", \"name\": \"RYU\"}\n",
    "}\n",
    "\n",
    "# Create a figure and two subplots for plotting trench velocity data.\n",
    "# `gs` defines a 2x1 grid layout for the subplots.\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "total_points_plotted = 0  # Variable to record the total number of plotted points.\n",
    "\n",
    "# Filter out rows with NaN values in the \"age\" column.\n",
    "mask_age = (~subduction_data_resampled[\"age\"].isna())\n",
    "total_points_plotted += len(subduction_data_resampled[mask_age])  # Count valid points.\n",
    "subduction_data_resampled_valid = subduction_data_resampled[mask_age]  # Store valid data.\n",
    "\n",
    "# Obtain a sorted list of unique subducting plate IDs from the valid data.\n",
    "unique_subducting_ids = subduction_data_resampled_valid.subducting_pid.unique()\n",
    "labels = []\n",
    "patches = []\n",
    "unique_subducting_ids.sort()  # Sort the unique subducting plate IDs.\n",
    "print(unique_subducting_ids)\n",
    "\n",
    "# Lookup and store subducting plate names based on their IDs.\n",
    "unique_subducting_names = []\n",
    "for i in range(len(unique_subducting_ids)):\n",
    "    subducting_id = unique_subducting_ids[i]\n",
    "    unique_subducting_names.append(GParseReconstruction.LookupNameByPid(int(subducting_id)))\n",
    "\n",
    "# Loop through each subducting plate ID and plot the corresponding trench velocity.\n",
    "for i in range(len(unique_subducting_ids)):\n",
    "    _name = unique_subducting_names[i]\n",
    "\n",
    "    subducting_id = unique_subducting_ids[i]\n",
    "    try:\n",
    "        plot_option_sub_dict = plot_options[int(subducting_id)]  # Get plot options for the ID.\n",
    "    except KeyError:\n",
    "        # If no specific plot option is found, use default settings.\n",
    "        print(\"Id %s not found, marked as TBD\" % int(subducting_id))\n",
    "        plot_option_sub_dict = {\"marker\": 'o',  \"markerfacecolor\": None, \"name\": \"TBD\"}\n",
    "\n",
    "    # Make an output for the plotting function to loop over the trench ids\n",
    "    plot_trench_pids = None; plot_option_list = None\n",
    "    if 'name' in plot_option_sub_dict:\n",
    "        # A subduction contains a single trench\n",
    "        plot_trench_pids = [None]\n",
    "        plot_option_list = [plot_option_sub_dict.copy()]\n",
    "    else:\n",
    "        # A subduction contains multiple trenches\n",
    "        plot_trench_pids = []\n",
    "        plot_option_list = []\n",
    "        for key, value in plot_option_sub_dict.items():\n",
    "            plot_trench_pids.append(key)\n",
    "            plot_option_list.append(value.copy())\n",
    "\n",
    "    # Loop over the trench ids and plot the markers\n",
    "    for i_tr in range(len(plot_trench_pids)):\n",
    "        trench_pid = plot_trench_pids[i_tr]\n",
    "        plot_option = plot_option_list[i_tr]\n",
    "        # We want trench_pid options to be flexible.\n",
    "        # It could be a - a value; b - a range and c - multiple values\n",
    "        # d - None\n",
    "        # Create a mask for the current subducting plate and plot its trench velocity.\n",
    "        # We allow a variation of 0.1 from the integar value\n",
    "        # mask1 - match the subducting id\n",
    "        # mask2 - match the trench pid condition.\n",
    "        mask1 = (abs(subduction_data_resampled.subducting_pid - subducting_id) < 0.1)\n",
    "        if trench_pid is None:\n",
    "            mask = mask1\n",
    "        elif type(trench_pid) == float or type(trench_pid) == int:\n",
    "            mask = mask1 & (abs(subduction_data_resampled.trench_pid - trench_pid) < 0.1)\n",
    "        elif type(trench_pid) == list:\n",
    "            # mutiple values\n",
    "            mask2 = (abs(subduction_data_resampled.trench_pid - trench_pid[0]) < 0.1)\n",
    "            for trench_sub_pid in trench_pid[1:]:\n",
    "                mask2 = mask2 | (abs(subduction_data_resampled.trench_pid - trench_sub_pid) < 0.1)\n",
    "            mask = mask1 & mask2\n",
    "        elif type(trench_pid) == tuple:\n",
    "            # a range\n",
    "            assert(len(trench_pid) == 2)\n",
    "            mask2 = ((subduction_data_resampled.trench_pid >= trench_pid[0]) & (subduction_data_resampled.trench_pid <= trench_pid[1]))\n",
    "            mask = mask1 & mask2\n",
    "        else:\n",
    "            raise ValueError(\"Type of trench pid is wrong. Possible types are [None, float, int, list, dict]\")\n",
    "        ages = subduction_data_resampled_valid.age[mask]\n",
    "        trench_velocities = subduction_data_resampled_valid.trench_velocity[mask]\n",
    "        near_distances = subduction_data_resampled_valid.near_distance[mask]\n",
    "        _patch = ax1.plot(ages, trench_velocities,\\\n",
    "                marker=plot_option[\"marker\"], markerfacecolor=plot_option[\"markerfacecolor\"],\\\n",
    "                markeredgecolor='black', markersize=10, linestyle='', label=plot_option[\"name\"])[0]\n",
    "        _patch_d = ax3.plot(near_distances, trench_velocities,\\\n",
    "                marker=plot_option[\"marker\"], markerfacecolor=plot_option[\"markerfacecolor\"],\\\n",
    "                markeredgecolor='black', markersize=10, linestyle='', label=plot_option[\"name\"])[0]\n",
    "        patches.append(_patch)\n",
    "\n",
    "i += 1  # Increment index.\n",
    "    \n",
    "# fix Ryuku\n",
    "# plot_option = {\"marker\": 'd',  \"markerfacecolor\": \"blue\", \"name\": \"RYU\"}\n",
    "# ages = [35.0, 38.0, 48.0, 50.0, 50.0]\n",
    "# trench_velocities = [3.0, 0.9, 1.2, 0.7, 0.9]\n",
    "# _patch = ax1.plot(ages, trench_velocities,\\\n",
    "#                 marker=plot_option[\"marker\"], markerfacecolor=plot_option[\"markerfacecolor\"],\\\n",
    "#                 markeredgecolor='red', markersize=10, linestyle=None, label=plot_option[\"name\"])[0]\n",
    "# patches.append(_patch)\n",
    "\n",
    "# Configure grid and legend for the second subplot.\n",
    "ax1.grid()\n",
    "ax3.grid()\n",
    "ax2.legend(handles=patches, bbox_to_anchor=(0.5, 0.5), loc='center', ncol=2, numpoints=1, frameon=False)\n",
    "\n",
    "# Output the total number of plotted points.\n",
    "print(\"Total plotted points: %d\" % total_points_plotted)\n",
    "\n",
    "# Set axis limits and labels for the first plot (trench velocity vs age).\n",
    "ax1.set_xlim([0, 160.0])\n",
    "ax1.set_ylim([-10.0, 10.0])\n",
    "ax3.set_ylim([-10.0, 10.0])\n",
    "ax1.set_xlabel(\"Age (Ma)\")\n",
    "ax1.set_ylabel(\"Trench Velocity Magnitude (cm/yr)\")\n",
    "ax3.set_ylabel(\"Trench Velocity Magnitude (cm/yr)\")\n",
    "\n",
    "# Save the figure to a PDF file with a name derived from the reconstruction parameters.\n",
    "fileout = os.path.join(RESULT_DIR, \"gplate_subduction_zones\", \"subduction_distribution_t_%.2e_edge_%.2f_section_%.2f.pdf\"\\\n",
    "     % (reconstruction_time, arc_length_edge, arc_length_resample_section))\n",
    "fig.savefig(fileout)\n",
    "print(\"figure saved: %s\" % fileout)\n",
    "\n",
    "# Save the subducting plate ID and names to a CSV file for future reference.\n",
    "csv_out = os.path.join(RESULT_DIR, \"gplate_subduction_zones\", \"subduction_distribution_t_%.2e_edge_%.2f_section_%.2f.csv\"\\\n",
    "     % (reconstruction_time, arc_length_edge, arc_length_resample_section))\n",
    "unique_data = {\n",
    "    \"pid\": unique_subducting_ids,\n",
    "    'name': unique_subducting_names\n",
    "}\n",
    "df_unique_data = pd.DataFrame(unique_data)\n",
    "df_unique_data.to_csv(csv_out)\n",
    "print(\"csv file saved: %s\" % csv_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-gplate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
